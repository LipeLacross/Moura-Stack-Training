## üåê [English Version of README](README_EN.md)

# Moura-Stack-Training

Projeto desenvolvido para demonstrar compet√™ncias t√©cnicas (Moura) em **APIs (FastAPI)**, **dashboard em Jinja**, **SQL avan√ßado em PostgreSQL** (consultas, trigger, procedure), **ETL com Prefect**, **Big Data com PySpark**, **exporta√ß√µes em Parquet/CSV e Excel**, al√©m de **modelagem anal√≠tica com dbt**. O projeto tamb√©m integra **Power BI embed**, estat√≠stica (Pearson/OLS) e machine learning (regress√£o linear com Scikit-learn).

---

## üî® Funcionalidades do Projeto

* **API REST (FastAPI)**
  Endpoints: `/health`, `/metrics/sales`, `/metrics/summary`, `/stats/pearson`, `/stats/ols`, `/ml/train`, `/ml/predict`, `/etl/run`, `/gold/export`, `/export/excel`, `/spark/run`.
* **Dashboard Jinja** com KPIs, gr√°ficos interativos (Plotly) e est√°ticos (Matplotlib/Seaborn), Chart.js e D3.js.
* **Banco de Dados PostgreSQL**: tabela `sales`, trigger `set_total` e procedure `upsert_product_revenue`.
* **ETL com Prefect**: fluxo para gerar Parquet/CSV (camada Gold).
* **PySpark**: job para processamento em larga escala.
* **Export Excel**: endpoint usando OpenPyXL.
* **dbt**: modelos `stg_sales` (silver) e `fct_sales` (gold).
* **Infraestrutura**: Docker/Docker Compose prontos para uso.

---

### üì∏ Exemplo Visual do Projeto

<div align="center">
  <img src="docs/screenshot-dashboard-1.png" alt="Screenshot 2025-07-03 132707" width="80%" style="margin: 16px 0; border-radius: 10px;">
  <img src="docs/screenshot-dashboard-2.png" alt="Screenshot 2025-07-03 130932" width="80%" style="margin: 16px 0; border-radius: 10px;">
</div>

---

## ‚úîÔ∏è T√©cnicas e Tecnologias Utilizadas

* **Linguagem:** Python 3.11+
* **Backend:** FastAPI, Pydantic, Uvicorn, SQLAlchemy
* **Banco de Dados:** PostgreSQL (psycopg2)
* **Frontend/BI:** Jinja + Power BI embed
* **An√°lises:** Pandas, NumPy, Plotly, Matplotlib, Seaborn, Statsmodels, Chart.js, D3.js
* **ML:** Scikit-learn (Regress√£o Linear)
* **ETL/Big Data:** Prefect, PySpark, Parquet (PyArrow)
* **Modelagem de Dados:** dbt
* **Dev/Qualidade:** Black, Docker

---

## üìÅ Estrutura do Projeto

* **app/backend/**

  * `main.py`: instancia FastAPI, configura√ß√µes e dashboard Jinja.
  * `db.py`: conex√£o com PostgreSQL via SQLAlchemy.
  * `models.py`: schemas Pydantic.
  * *(rotas organizadas em m√≥dulos importados pelo `main.py`)*.
* **app/core/**

  * `utils.py`: utilit√°rios de inicializa√ß√£o/checagem de banco.
* **app/services/**

  * `data.py`: carregamento/transforma√ß√µes, m√©tricas e modelos ML.
  * `etl.py`, `metrics.py`, `ml.py`, `stats.py`: servi√ßos especializados.
* **app/templates/**

  * `base.html`: layout base.
  * `dashboard.html`: dashboard interativo.
* **data/**

  * `sample_sales.csv`: dados de exemplo.
* **dbt/**

  * `dbt_project.yml`: configura√ß√£o.
  * `models/`

    * `stg_sales.sql`: camada silver.
    * `fct_sales.sql`: camada gold.
* **scripts/generate\_charts/**

  * `matplotlib_chart.py`, `plotly_chart.py`, `seaborn_chart.py`, `statistics_chart.py`, `ml_regression.py`, `pyspark_agg.py`.
* **sql/**

  * `01_init.sql`: cria√ß√£o de tabela, trigger e procedure.
* **public/**

  * `moura-logo.ico`: √≠cone do site.
  * `plotly.png`, `seaborn.png`, `statistics.png`, `matplotlib.png`, `moura-logo-1-2048x1651.png`.
* **Infraestrutura**

  * `requirements.txt`, `pyproject.toml`
  * `Dockerfile`, `docker-compose.yml`
  * `.env` e `.env.example`

---

## üõ†Ô∏è Abrir e rodar o projeto

Para iniciar o projeto localmente, siga os passos abaixo:

1. **Pr√©-requisitos**

   * Python 3.11+
   * PostgreSQL instalado
   * (Opcional) Docker/Docker Compose
   * (Opcional) Java 17 para PySpark

2. **Clone o Reposit√≥rio**

```bash
git clone <URL_DO_REPOSITORIO>
cd moura-stack-training
```

3. **Configura√ß√£o do ambiente**

```bash
python -m venv .venv
. .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install -r requirements.txt
cp .env.example .env
```

Edite o `.env` e configure:

* `DATABASE_URL=postgresql+psycopg2://user:pass@host:5432/dbname`
* `ETL_SOURCE=csv` ou `postgres`
* `POWER_BI_EMBED_URL=...`

4. **Rodar o Banco**

```bash
psql "postgresql://user:pass@host:5432/dbname" -f sql/01_init.sql
```

5. **Iniciar o Backend**

```bash
uvicorn app.backend.main:app --reload --port 8000
# http://localhost:8000/docs
```

6. **Dashboard Jinja**
   Abra no navegador:

```
http://localhost:8000/dashboard
```

7. **ETL & Exporta√ß√µes**

```bash
curl -X POST http://localhost:8000/etl/run
curl -X POST http://localhost:8000/gold/export
curl -X POST http://localhost:8000/export/excel
```

8. **Rodar Spark (opcional)**

```bash
python app/backend/spark_job.py
```

---

## üåê Deploy

* **Docker (local)**

```bash
docker compose up --build
```

* **Nuvem**

  * **API**: deploy via Docker em Railway, Render, Fly.io ou AWS ECS.
  * **Banco**: use PostgreSQL gerenciado (RDS, CloudSQL, Azure).
  * **Power BI**: configure `POWER_BI_EMBED_URL`.
  * **dbt**: aponte para o Postgres da nuvem e rode `dbt run`.

